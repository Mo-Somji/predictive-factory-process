{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ab3522-ab76-422f-ac63-f9a99d12a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41781a84-3ff5-4e33-93e5-f0b48d6d327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two function to load the baseline RandomForest model and train/test data\n",
    "\n",
    "def load_model(best_model_path):\n",
    "    best_model = joblib.load(best_model_path)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def load_data(X_train_file_path, X_test_file_path, y_train_file_path, y_test_file_path):\n",
    "    X_train = pd.read_csv(X_train_file_path)\n",
    "    X_test = pd.read_csv(X_test_file_path)\n",
    "    y_train = pd.read_csv(y_train_file_path).squeeze()\n",
    "    y_test = pd.read_csv(y_test_file_path).squeeze()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21010ca0-9c7b-4e1b-9d82-0feee1a09abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the hyperparameter tuning\n",
    "\n",
    "def tune_hyperparameters(X_train, y_train):\n",
    "    # Define hyperparameters\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [50, 100, 200, 300, 500],\n",
    "        \"max_depth\": [10, 20, 30, None],\n",
    "        \"min_samples_split\": [2, 5, 10, 15],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 6, 8],\n",
    "        \"bootstrap\": [True, False],\n",
    "        \"max_features\": ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    search = GridSearchCV(base_model, param_grid, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1, verbose=2, return_train_score=True)\n",
    "\n",
    "    # Performing hyperparameter tuning\n",
    "    search.fit(X_train, y_train)\n",
    "    print('Hyperparameter tuning has now finished')\n",
    "\n",
    "    return search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae7354c-4003-4268-8ddc-d6d2d5cec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every set of hyperparameters (from cv_results_), re-train the model on the training data,\n",
    "# evaluate it on the test data (computing MAE), and select the candidate with the lowest test MAE.\n",
    "\n",
    "def best_model_evaluation(cv_results, X_train, X_test, y_train, y_test):\n",
    "    print('evaluating grid search results for best test MAE')\n",
    "    params_list = cv_results['params']\n",
    "    # Convert the (negative) mean training scores to positive MAE values\n",
    "    train_mae_list = [-score for score in cv_results['mean_train_score']]\n",
    "\n",
    "    def evaluate_candidate(params):\n",
    "        model = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_mae = mean_absolute_error(y_test, y_pred)\n",
    "        return model, params, test_mae\n",
    "\n",
    "    # Evaluate all candidate hyperparameter combinations in parallel.\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(evaluate_candidate)(params) for params in params_list\n",
    "    )\n",
    "\n",
    "    # Assemble all results into a DataFrame for inspection or saving.\n",
    "    test_mae_list = [res[2] for res in results]\n",
    "    all_results = [\n",
    "        {\"params\": p, \"train_mae\": t, \"test_mae\": te}\n",
    "        for p, t, te in zip(params_list, train_mae_list, test_mae_list)\n",
    "    ]\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return results_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7482a482-9c80-4ec8-bd1e-9a58623e0e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1600 candidates, totalling 8000 fits\n",
      "Hyperparameter tuning has now finished\n",
      "evaluating grid search results for best test MAE\n",
      "Best hyperparameters (based on test MAE): {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Test MAE for the best model: 0.11448929596690186\n",
      "âœ… Best Tuned Model saved as 'best_tuned_model.pkl'\n",
      "âœ… Hyperparameter tuning results saved to 'hyperparameter_results.csv'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Paths to model and training data defined below\n",
    "    best_model_path = '../Models/RandomForest_best.pkl'\n",
    "    X_train_file_path = '../Data/X_train_dataset.csv'\n",
    "    X_test_file_path = '../Data/X_test_dataset.csv'\n",
    "    y_train_file_path = '../Data/y_train_dataset.csv'\n",
    "    y_test_file_path = '../Data/y_test_dataset.csv'\n",
    "\n",
    "    # Executing function to load best RandomForest model\n",
    "    best_model = load_model(best_model_path)\n",
    "\n",
    "    # Executing function to load train and test data\n",
    "    X_train, X_test, y_train, y_test = load_data(X_train_file_path, X_test_file_path, y_train_file_path, y_test_file_path)\n",
    "\n",
    "    # Executing function to perform hyperparameter tuning\n",
    "    cv_results = tune_hyperparameters(X_train, y_train)\n",
    "\n",
    "    # Executing function to evaluate the hyperparameter tuning results\n",
    "    results_df = best_model_evaluation(\n",
    "        cv_results, X_train, X_test, y_train, y_test\n",
    "    )\n",
    "    \n",
    "    # Saving hyperparameter tuning results\n",
    "    results_df.to_csv(\"../Data/hyperparameter_results.csv\", index=False)\n",
    "    print(\"ðŸ’¾ Hyperparameter tuning results saved to 'hyperparameter_results.csv'\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cb466-64f0-4b81-b1bd-2dcbd65578e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5392d5-aa4e-4769-a84c-ce148045b350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
